# Non-Autoregressive Neural Machine Translation with Reinforcement Learning 

## Overview
The project implements non-autoregressive (NA) Neural Machine Translation (NMT) using Reinforcement Learning (RL) objectives. Traditionally, NMT models are autoregressive, generating translations one word at a time based on the previously generated words. However, this sequential nature leads to a high computational cost during inference. Non-autoregressive models were proposed to address this issue, generating all words in the translation simultaneously and thus significantly speeding up inference [[1]](#1).

An approach to boost the performance of NA-NMT is via an RL-based optimization strategy using sentence-level reward metrics. These reward metrics provide a means of assessing the quality of the translations generated by the model. This project follows the approach by Shao et al., where the training of the NA-NMT model is formulated as a reinforcement learning problem, and sentence-level rewards are used as a signal to guide the model towards better translations [[2]](#2).

In this project, we implement NAT-NMT with RL using the following reward metrics: BLEU, METEOR, ROUGE, WER, BERTscore, BLEURT & COMET. We use the WMT 2014 dataset for our experiments, with German and English as the source and target languages, respectively [[6]](#6). 

## Code
This repository is a fork of the [fairseq](https://github.com/facebookresearch/fairseq) repository by Facebook AI Research. Fairseq(-py) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks.

### Organization
The folder `fairseq_easy_extend` contains the main configurations, criterions, data classes, and models. The various reward metrics are implemented in the RLCriterion class in `fairseq_easy_extend/criterions/rl_criterion.py`. The training configuration for the NAT model is available in `models/nat/cmlm_config.yaml`.

### Steps to reproduce:
1. Clone the repository.
2. Install the environment: `conda env create -f env.yml`.
3. Download the WMT 2014 dataset from [this link](https://drive.google.com/drive/folders/13PjvDNiPpE1p0MZQXFXO72Q94TQ1uTwa?usp=drive_link) and place it in the root directory of the project.
4. Download the pre-trained NAT CMLM model from [here](https://drive.google.com/file/d/1ymVxSCZksIb1ApoV2hH0bU3gdIxG5j6N/view?usp=drive_link) and place it in `models/nat/checkpoints/checkpoint_pretrained.pt`.
5. Set the reward metric, learning rate, batch size, and other training configuration parameters in `cmlm_config.yaml`.
6. Train (fine-tune) the NAT model using: 
`python train.py --config-dir "fairseq_easy_extend/models/nat/" --config-name "cmlm_config.yaml"`.
7. Evaluate the saved checkpoint using: 
`python decode.py iwslt14.tokenized.de-en --source-lang de --target-lang en --task translation_lev --iter-decode-max-iter 9 --gen-subset test --print-step --remove-bpe --tokenizer moses --scoring <scoring-metric>  --path /path/to/saved/checkpoint`. Replace `<scoring-metric>` by the fairseq scoring metric (bleu, meteor, wer or bert_score) and `/path/to/saved/checkpoint` by the path to the saved checkpoint.

We also provide a jupyter notebook `nanmt-fairseq.ipynb` with these bash commands.

## References
<a id="1">[1]</a> Non-Autoregressive Neural Machine Translation. Gu, Jiatao. 2018. Association for Computational Linguistics.

<a id="2">[2]</a> Sequence-Level Training for Non-Autoregressive Neural Machine Translation. Chenze Shao, Yang Feng, Jinchao Zhang, Fandong Meng, Jie Zhou; . Computational Linguistics 2021

[3] Improving Autoregressive NMT with Non-Autoregressive Model. Zhou, Long; Zhang, Jiajun; Zong, Chengqing. 2020. Proceedings of the First Workshop on Automatic Simultaneous Translation.

[4] Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation. 2021. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.

[5] To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for Machine Translation. Kocmi et al. 2021. Sixth Conference on Machine Translation.

<a id="6">[6]</a> [Findings of the 2014 Workshop on Statistical Machine Translation](https://aclanthology.org/W14-3302) (Bojar et al., WMT 2014)